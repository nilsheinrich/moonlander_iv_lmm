{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fca858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import itertools\n",
    "import arviz as az\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as  mpatches\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ccefa",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910fcfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/soc_data_iv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210fec27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.54107029051394, 2.7537963271560457)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data[data.done == True].time_played), np.std(data[data.done == True].time_played)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd7cd0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'level', 'trial', 'time_played', 'N_attempt', 'done',\n",
       "       'expectancy', 'SoC', 'crashed', 'N_drift', 'N_prior_crashs',\n",
       "       'SoC_last_trial', 'trials_since_last_crash', 'crashed_in_last_trial',\n",
       "       'consecutive_crash_success', 'N_consecutive_crash_success',\n",
       "       'Neuroticism', 'Extraversion', 'Openness', 'Conscientiousness',\n",
       "       'Agreeableness', 'Neuroticism_norm', 'Extraversion_norm',\n",
       "       'Openness_norm', 'Conscientiousness_norm', 'Agreeableness_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86db6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's annotate the data a little bit and make it more concise\n",
    "df = data.dropna(subset=[\"ID\", \"expectancy\", \"N_drift\", \"SoC\", \"SoC_last_trial\", \"crashed\", \"crashed_in_last_trial\", \"N_consecutive_crash_success\"]).copy()\n",
    "\n",
    "# Encode IDs\n",
    "df[\"ID_idx\"] = pd.Categorical(df[\"ID\"]).codes\n",
    "n_participants = df[\"ID_idx\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a635e",
   "metadata": {},
   "source": [
    "# Bayesian updating process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4e0a93",
   "metadata": {},
   "source": [
    "- we will treat SoC as normally distributed posterior.\n",
    "- we will split the data by participant ID.\n",
    "- for every row within the participant data we will model the Bayesian updating process.\n",
    " <br />\n",
    "\n",
    "- we will assess the weighting of the likelihood assuming the prior weight is =1. This will tell us whether individual participants relied more on their prior or their inferred performance when rating their Sense of Control (SoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7d504",
   "metadata": {},
   "source": [
    "But to find out the difference in weighting of prior and likelihood, we first have to define prior and likelihood, that is specify what constitute them. For this, we can refer to our final selected linear mixed models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befbee89",
   "metadata": {},
   "source": [
    "$prior \\approx N_{(crash-success)} + SoC_{t-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c95615",
   "metadata": {},
   "source": [
    "$likelihood \\approx N_{Drift} + crashed_{(0,1)} + crashed_{t-1;0,1} + N_{(crash-success)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d45c2c",
   "metadata": {},
   "source": [
    "## Hierarchical Bayesian Model with dynamic likelihood weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490f7cb",
   "metadata": {},
   "source": [
    "Let the log weight evolve linearly across trials:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494ab697",
   "metadata": {},
   "source": [
    "$log(w){_i,_t} = \\alpha{_i} + \\beta{_i} * trial{_i,_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab65858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/crk0j_p52yq850yynjpq93wm0000gn/T/ipykernel_6103/880337503.py:46: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(1000, tune=1000, target_accept=0.95)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, b_drift, b_crashed_prev, b_crashed, b_n_consec, b_soc_last, beta, alpha, sigma_beta, mu_beta, sigma_alpha, mu_alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='913' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      11.41% [913/8000 00:01<00:14 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/quadpotential.py:224: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  np.divide(1, self._stds, out=self._inv_stds)\n",
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/quadpotential.py:203: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.multiply(self._var, x, out=out)\n",
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/quadpotential.py:224: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  np.divide(1, self._stds, out=self._inv_stds)\n",
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/quadpotential.py:203: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.multiply(self._var, x, out=out)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Chain 0 failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py\", line 137, in run\n    self._start_loop()\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py\", line 191, in _start_loop\n    point, stats = self._compute_point()\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py\", line 216, in _compute_point\n    point, stats = self._step_method.step(self._point)\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/arraystep.py\", line 276, in step\n    apoint, stats = self.astep(array)\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/base_hmc.py\", line 147, in astep\n    self.potential.raise_ok(self._logp_dlogp_func._ordering.vmap)\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/quadpotential.py\", line 272, in raise_ok\n    raise ValueError(\"\\n\".join(errmsg))\nValueError: Mass matrix contains zeros on the diagonal. \nThe derivative of RV `beta`.ravel()[6] is zero.\nThe derivative of RV `beta`.ravel()[7] is zero.\nThe derivative of RV `beta`.ravel()[9] is zero.\nThe derivative of RV `beta`.ravel()[11] is zero.\nThe derivative of RV `beta`.ravel()[12] is zero.\nThe derivative of RV `beta`.ravel()[15] is zero.\nThe derivative of RV `beta`.ravel()[16] is zero.\nThe derivative of RV `alpha`.ravel()[6] is zero.\nThe derivative of RV `mu_alpha`.ravel()[0] is zero.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: Mass matrix contains zeros on the diagonal. \nThe derivative of RV `beta`.ravel()[6] is zero.\nThe derivative of RV `beta`.ravel()[7] is zero.\nThe derivative of RV `beta`.ravel()[9] is zero.\nThe derivative of RV `beta`.ravel()[11] is zero.\nThe derivative of RV `beta`.ravel()[12] is zero.\nThe derivative of RV `beta`.ravel()[15] is zero.\nThe derivative of RV `beta`.ravel()[16] is zero.\nThe derivative of RV `alpha`.ravel()[6] is zero.\nThe derivative of RV `mu_alpha`.ravel()[0] is zero.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# defining deterministic variable to keep true SoC \u001b[39;00m\n\u001b[1;32m     44\u001b[0m SoC_pred \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mDeterministic(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoC_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m, mu_soc)\n\u001b[0;32m---> 46\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/sampling.py:559\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, idata_kwargs, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m _print_step_hierarchy(step)\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m     trace \u001b[38;5;241m=\u001b[39m \u001b[43m_mp_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparallel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError:\n\u001b[1;32m    561\u001b[0m     _log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not pickle model, sampling singlethreaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/sampling.py:1477\u001b[0m, in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, callback, discard_tuned_samples, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m sampler:\n\u001b[0;32m-> 1477\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m draw \u001b[38;5;129;01min\u001b[39;00m sampler:\n\u001b[1;32m   1478\u001b[0m             trace \u001b[38;5;241m=\u001b[39m traces[draw\u001b[38;5;241m.\u001b[39mchain \u001b[38;5;241m-\u001b[39m chain]\n\u001b[1;32m   1479\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m trace\u001b[38;5;241m.\u001b[39msupports_sampler_stats \u001b[38;5;129;01mand\u001b[39;00m draw\u001b[38;5;241m.\u001b[39mstats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py:479\u001b[0m, in \u001b[0;36mParallelSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_draws)\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active:\n\u001b[0;32m--> 479\u001b[0m     draw \u001b[38;5;241m=\u001b[39m \u001b[43mProcessAdapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_draw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_active\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     proc, is_last, draw, tuning, stats, warns \u001b[38;5;241m=\u001b[39m draw\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_draws \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py:359\u001b[0m, in \u001b[0;36mProcessAdapter.recv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m         error \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m proc\u001b[38;5;241m.\u001b[39mchain)\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mold_error\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m msg[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwriting_done\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    361\u001b[0m     proc\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Chain 0 failed."
     ]
    }
   ],
   "source": [
    "n_participants = df[\"ID_idx\"].nunique()\n",
    "\n",
    "with pm.Model() as time_varying_model:\n",
    "    # hyperpriors\n",
    "    mu_alpha = pm.Normal(\"mu_alpha\", 0, 1)\n",
    "    sigma_alpha = pm.HalfNormal(\"sigma_alpha\", 1)\n",
    "    \n",
    "    mu_beta = pm.Normal(\"mu_beta\", 0, 1)\n",
    "    sigma_beta = pm.HalfNormal(\"sigma_beta\", 1)\n",
    "\n",
    "    # per-participant intercept and slope\n",
    "    alpha = pm.Normal(\"alpha\", mu=mu_alpha, sigma=sigma_alpha, shape=n_participants)\n",
    "    beta = pm.Normal(\"beta\", mu=mu_beta, sigma=sigma_beta, shape=n_participants)\n",
    "\n",
    "    # trial-level weight per row (indexed by participant and trial)\n",
    "    trial_idxs = df[\"trial\"].values\n",
    "    participant_idxs = df[\"ID_idx\"].values\n",
    "\n",
    "    log_w = alpha[participant_idxs] + beta[participant_idxs] * trial_idxs\n",
    "    w = pm.Deterministic(\"w\", pm.math.exp(log_w))  # ensures w > 0\n",
    "    \n",
    "    # --- Linear prior: SoC_last_trial + N_consecutive_crash_success ---\n",
    "    b_soc_last = pm.Normal(\"b_soc_last\", 0, 1)\n",
    "    b_n_consec = pm.Normal(\"b_n_consec\", 0, 1)\n",
    "    prior = b_soc_last * df[\"SoC_last_trial\"].values + b_n_consec * df[\"N_consecutive_crash_success\"].values\n",
    "\n",
    "    # --- Linear likelihood: crashed + crashed_in_last_trial + N_drift ---\n",
    "    b_crashed = pm.Normal(\"b_crashed\", 0, 1)\n",
    "    b_crashed_prev = pm.Normal(\"b_crashed_prev\", 0, 1)\n",
    "    b_drift = pm.Normal(\"b_drift\", 0, 1)\n",
    "    likelihood = (\n",
    "        b_crashed * df[\"crashed\"].values +\n",
    "        b_crashed_prev * df[\"crashed_in_last_trial\"].values +\n",
    "        b_drift * df[\"N_drift\"].values\n",
    "    )\n",
    "    \n",
    "    # --- Bayesian update to compute SoC ---\n",
    "    mu_soc = (prior + w * likelihood) / (1 + w)\n",
    "    \n",
    "    sigma = pm.HalfNormal(\"sigma\", 0.1)\n",
    "    SoC_obs = pm.Normal(\"SoC_obs\", mu=mu_soc, sigma=sigma, observed=df[\"SoC\"].values)\n",
    "    \n",
    "    # defining deterministic variable to keep true SoC \n",
    "    SoC_pred = pm.Deterministic(\"SoC_pred\", mu_soc)\n",
    "\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.95)\n",
    "    #trace = pm.sample(1000, target_accept=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3048bbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/crk0j_p52yq850yynjpq93wm0000gn/T/ipykernel_6103/3487145949.py:38: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(1000, tune=1000, target_accept=0.95)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, beta, alpha, sigma_beta, mu_beta, sigma_alpha, mu_alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='820' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.25% [820/8000 00:00<00:08 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/quadpotential.py:224: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  np.divide(1, self._stds, out=self._inv_stds)\n",
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/quadpotential.py:203: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.multiply(self._var, x, out=out)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Chain 2 failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py\", line 137, in run\n    self._start_loop()\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py\", line 191, in _start_loop\n    point, stats = self._compute_point()\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py\", line 216, in _compute_point\n    point, stats = self._step_method.step(self._point)\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/arraystep.py\", line 276, in step\n    apoint, stats = self.astep(array)\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/base_hmc.py\", line 147, in astep\n    self.potential.raise_ok(self._logp_dlogp_func._ordering.vmap)\n  File \"/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/step_methods/hmc/quadpotential.py\", line 272, in raise_ok\n    raise ValueError(\"\\n\".join(errmsg))\nValueError: Mass matrix contains zeros on the diagonal. \nThe derivative of RV `beta`.ravel()[0] is zero.\nThe derivative of RV `beta`.ravel()[1] is zero.\nThe derivative of RV `beta`.ravel()[2] is zero.\nThe derivative of RV `beta`.ravel()[3] is zero.\nThe derivative of RV `beta`.ravel()[4] is zero.\nThe derivative of RV `beta`.ravel()[5] is zero.\nThe derivative of RV `beta`.ravel()[6] is zero.\nThe derivative of RV `beta`.ravel()[7] is zero.\nThe derivative of RV `beta`.ravel()[8] is zero.\nThe derivative of RV `beta`.ravel()[9] is zero.\nThe derivative of RV `beta`.ravel()[10] is zero.\nThe derivative of RV `beta`.ravel()[11] is zero.\nThe derivative of RV `beta`.ravel()[12] is zero.\nThe derivative of RV `beta`.ravel()[13] is zero.\nThe derivative of RV `beta`.ravel()[14] is zero.\nThe derivative of RV `beta`.ravel()[15] is zero.\nThe derivative of RV `beta`.ravel()[16] is zero.\nThe derivative of RV `beta`.ravel()[17] is zero.\nThe derivative of RV `beta`.ravel()[18] is zero.\nThe derivative of RV `beta`.ravel()[19] is zero.\nThe derivative of RV `beta`.ravel()[20] is zero.\nThe derivative of RV `beta`.ravel()[21] is zero.\nThe derivative of RV `beta`.ravel()[22] is zero.\nThe derivative of RV `beta`.ravel()[23] is zero.\nThe derivative of RV `alpha`.ravel()[0] is zero.\nThe derivative of RV `alpha`.ravel()[1] is zero.\nThe derivative of RV `alpha`.ravel()[2] is zero.\nThe derivative of RV `alpha`.ravel()[3] is zero.\nThe derivative of RV `alpha`.ravel()[4] is zero.\nThe derivative of RV `alpha`.ravel()[5] is zero.\nThe derivative of RV `alpha`.ravel()[6] is zero.\nThe derivative of RV `alpha`.ravel()[7] is zero.\nThe derivative of RV `alpha`.ravel()[8] is zero.\nThe derivative of RV `alpha`.ravel()[9] is zero.\nThe derivative of RV `alpha`.ravel()[10] is zero.\nThe derivative of RV `alpha`.ravel()[11] is zero.\nThe derivative of RV `alpha`.ravel()[12] is zero.\nThe derivative of RV `alpha`.ravel()[13] is zero.\nThe derivative of RV `alpha`.ravel()[14] is zero.\nThe derivative of RV `alpha`.ravel()[15] is zero.\nThe derivative of RV `alpha`.ravel()[16] is zero.\nThe derivative of RV `alpha`.ravel()[17] is zero.\nThe derivative of RV `alpha`.ravel()[18] is zero.\nThe derivative of RV `alpha`.ravel()[19] is zero.\nThe derivative of RV `alpha`.ravel()[20] is zero.\nThe derivative of RV `alpha`.ravel()[21] is zero.\nThe derivative of RV `alpha`.ravel()[22] is zero.\nThe derivative of RV `alpha`.ravel()[23] is zero.\nThe derivative of RV `sigma_beta_log__`.ravel()[0] is zero.\nThe derivative of RV `mu_beta`.ravel()[0] is zero.\nThe derivative of RV `sigma_alpha_log__`.ravel()[0] is zero.\nThe derivative of RV `mu_alpha`.ravel()[0] is zero.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: Mass matrix contains zeros on the diagonal. \nThe derivative of RV `beta`.ravel()[0] is zero.\nThe derivative of RV `beta`.ravel()[1] is zero.\nThe derivative of RV `beta`.ravel()[2] is zero.\nThe derivative of RV `beta`.ravel()[3] is zero.\nThe derivative of RV `beta`.ravel()[4] is zero.\nThe derivative of RV `beta`.ravel()[5] is zero.\nThe derivative of RV `beta`.ravel()[6] is zero.\nThe derivative of RV `beta`.ravel()[7] is zero.\nThe derivative of RV `beta`.ravel()[8] is zero.\nThe derivative of RV `beta`.ravel()[9] is zero.\nThe derivative of RV `beta`.ravel()[10] is zero.\nThe derivative of RV `beta`.ravel()[11] is zero.\nThe derivative of RV `beta`.ravel()[12] is zero.\nThe derivative of RV `beta`.ravel()[13] is zero.\nThe derivative of RV `beta`.ravel()[14] is zero.\nThe derivative of RV `beta`.ravel()[15] is zero.\nThe derivative of RV `beta`.ravel()[16] is zero.\nThe derivative of RV `beta`.ravel()[17] is zero.\nThe derivative of RV `beta`.ravel()[18] is zero.\nThe derivative of RV `beta`.ravel()[19] is zero.\nThe derivative of RV `beta`.ravel()[20] is zero.\nThe derivative of RV `beta`.ravel()[21] is zero.\nThe derivative of RV `beta`.ravel()[22] is zero.\nThe derivative of RV `beta`.ravel()[23] is zero.\nThe derivative of RV `alpha`.ravel()[0] is zero.\nThe derivative of RV `alpha`.ravel()[1] is zero.\nThe derivative of RV `alpha`.ravel()[2] is zero.\nThe derivative of RV `alpha`.ravel()[3] is zero.\nThe derivative of RV `alpha`.ravel()[4] is zero.\nThe derivative of RV `alpha`.ravel()[5] is zero.\nThe derivative of RV `alpha`.ravel()[6] is zero.\nThe derivative of RV `alpha`.ravel()[7] is zero.\nThe derivative of RV `alpha`.ravel()[8] is zero.\nThe derivative of RV `alpha`.ravel()[9] is zero.\nThe derivative of RV `alpha`.ravel()[10] is zero.\nThe derivative of RV `alpha`.ravel()[11] is zero.\nThe derivative of RV `alpha`.ravel()[12] is zero.\nThe derivative of RV `alpha`.ravel()[13] is zero.\nThe derivative of RV `alpha`.ravel()[14] is zero.\nThe derivative of RV `alpha`.ravel()[15] is zero.\nThe derivative of RV `alpha`.ravel()[16] is zero.\nThe derivative of RV `alpha`.ravel()[17] is zero.\nThe derivative of RV `alpha`.ravel()[18] is zero.\nThe derivative of RV `alpha`.ravel()[19] is zero.\nThe derivative of RV `alpha`.ravel()[20] is zero.\nThe derivative of RV `alpha`.ravel()[21] is zero.\nThe derivative of RV `alpha`.ravel()[22] is zero.\nThe derivative of RV `alpha`.ravel()[23] is zero.\nThe derivative of RV `sigma_beta_log__`.ravel()[0] is zero.\nThe derivative of RV `mu_beta`.ravel()[0] is zero.\nThe derivative of RV `sigma_alpha_log__`.ravel()[0] is zero.\nThe derivative of RV `mu_alpha`.ravel()[0] is zero.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m SoC_obs \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoC_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, mu\u001b[38;5;241m=\u001b[39mmu_soc, sigma\u001b[38;5;241m=\u001b[39msigma, observed\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoC\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     36\u001b[0m SoC_pred \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mDeterministic(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoC_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m, mu_soc)\n\u001b[0;32m---> 38\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/sampling.py:559\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, idata_kwargs, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m _print_step_hierarchy(step)\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m     trace \u001b[38;5;241m=\u001b[39m \u001b[43m_mp_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparallel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError:\n\u001b[1;32m    561\u001b[0m     _log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not pickle model, sampling singlethreaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/sampling.py:1477\u001b[0m, in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, callback, discard_tuned_samples, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m sampler:\n\u001b[0;32m-> 1477\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m draw \u001b[38;5;129;01min\u001b[39;00m sampler:\n\u001b[1;32m   1478\u001b[0m             trace \u001b[38;5;241m=\u001b[39m traces[draw\u001b[38;5;241m.\u001b[39mchain \u001b[38;5;241m-\u001b[39m chain]\n\u001b[1;32m   1479\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m trace\u001b[38;5;241m.\u001b[39msupports_sampler_stats \u001b[38;5;129;01mand\u001b[39;00m draw\u001b[38;5;241m.\u001b[39mstats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py:479\u001b[0m, in \u001b[0;36mParallelSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_draws)\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active:\n\u001b[0;32m--> 479\u001b[0m     draw \u001b[38;5;241m=\u001b[39m \u001b[43mProcessAdapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_draw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_active\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     proc, is_last, draw, tuning, stats, warns \u001b[38;5;241m=\u001b[39m draw\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_draws \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.9/site-packages/pymc3/parallel_sampling.py:359\u001b[0m, in \u001b[0;36mProcessAdapter.recv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m         error \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m proc\u001b[38;5;241m.\u001b[39mchain)\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mold_error\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m msg[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwriting_done\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    361\u001b[0m     proc\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Chain 2 failed."
     ]
    }
   ],
   "source": [
    "with pm.Model() as time_varying_model:\n",
    "    # indexing data\n",
    "    trial_idxs = pm.Data(\"trial_idxs\", df[\"trial\"].values)\n",
    "    participant_idxs = pm.Data(\"participant_idxs\", df[\"ID_idx\"].values)\n",
    "\n",
    "    # hyperpriors\n",
    "    mu_alpha = pm.Normal(\"mu_alpha\", 0, 1)\n",
    "    sigma_alpha = pm.HalfNormal(\"sigma_alpha\", 1)\n",
    "    \n",
    "    mu_beta = pm.Normal(\"mu_beta\", 0, 1)\n",
    "    sigma_beta = pm.HalfNormal(\"sigma_beta\", 1)\n",
    "\n",
    "    # per-participant intercept and slope\n",
    "    alpha = pm.Normal(\"alpha\", mu=mu_alpha, sigma=sigma_alpha, shape=n_participants)\n",
    "    beta = pm.Normal(\"beta\", mu=mu_beta, sigma=sigma_beta, shape=n_participants)\n",
    "    \n",
    "    # Trial- and participant-specific weight\n",
    "    log_w = alpha[participant_idxs] + beta[participant_idxs] * trial_idxs\n",
    "    w = pm.Deterministic(\"w\", pm.math.exp(log_w))\n",
    "\n",
    "    # Observed data\n",
    "    SoC_last = pm.Data(\"SoC_last\", df[\"SoC_last_trial\"].values)\n",
    "    N_consec = pm.Data(\"N_consecutive\", df[\"N_consecutive_crash_success\"].values)\n",
    "    crashed = pm.Data(\"crashed\", df[\"crashed\"].values)\n",
    "    crashed_last = pm.Data(\"crashed_last\", df[\"crashed_in_last_trial\"].values)\n",
    "    N_drift = pm.Data(\"N_drift\", df[\"N_drift\"].values)\n",
    "\n",
    "    prior = SoC_last + N_consec\n",
    "    likelihood = crashed + crashed_last + N_drift\n",
    "\n",
    "    mu_soc = (prior + w * likelihood) / (1 + w)\n",
    "    \n",
    "    sigma = pm.HalfNormal(\"sigma\", 0.1)\n",
    "    SoC_obs = pm.Normal(\"SoC_obs\", mu=mu_soc, sigma=sigma, observed=df[\"SoC\"].values)\n",
    "\n",
    "    SoC_pred = pm.Deterministic(\"SoC_pred\", mu_soc)\n",
    "\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a268e82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/crk0j_p52yq850yynjpq93wm0000gn/T/ipykernel_6103/1440963533.py:36: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(1000, tune=1000, target_accept=0.95)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, beta, alpha, sigma_beta, mu_beta, sigma_alpha, mu_alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 01:58<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/heinrich/anaconda3/envs/datascience/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 162 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as simple_model:\n",
    "    # Indexing data\n",
    "    trial_idxs = pm.Data(\"trial_idxs\", df[\"trial\"].values)\n",
    "    participant_idxs = pm.Data(\"participant_idxs\", df[\"ID_idx\"].values)\n",
    "\n",
    "    # Inputs\n",
    "    expectancy = pm.Data(\"expectancy\", df[\"expectancy\"].values)\n",
    "    N_drift = pm.Data(\"N_drift\", df[\"N_drift\"].values)\n",
    "\n",
    "    # Hyperpriors\n",
    "    mu_alpha = pm.Normal(\"mu_alpha\", 0, 1)\n",
    "    sigma_alpha = pm.HalfNormal(\"sigma_alpha\", 1)\n",
    "    \n",
    "    mu_beta = pm.Normal(\"mu_beta\", 0, 1)\n",
    "    sigma_beta = pm.HalfNormal(\"sigma_beta\", 1)\n",
    "\n",
    "    # Per-participant parameters\n",
    "    alpha = pm.Normal(\"alpha\", mu=mu_alpha, sigma=sigma_alpha, shape=n_participants)\n",
    "    beta = pm.Normal(\"beta\", mu=mu_beta, sigma=sigma_beta, shape=n_participants)\n",
    "\n",
    "    # Weight (log scale to keep positive)\n",
    "    log_w = alpha[participant_idxs] + beta[participant_idxs] * trial_idxs\n",
    "    w = pm.Deterministic(\"w\", pm.math.exp(log_w))\n",
    "\n",
    "    # Weighted average of prior and likelihood\n",
    "    mu_soc = (expectancy + w * N_drift) / (1 + w)\n",
    "\n",
    "    # Observation model\n",
    "    sigma = pm.HalfNormal(\"sigma\", 0.1)\n",
    "    SoC_obs = pm.Normal(\"SoC_obs\", mu=mu_soc, sigma=sigma, observed=df[\"SoC\"].values)\n",
    "\n",
    "    # Predicted value\n",
    "    SoC_pred = pm.Deterministic(\"SoC_pred\", mu_soc)\n",
    "\n",
    "    # Sampling\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de91a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/crk0j_p52yq850yynjpq93wm0000gn/T/ipykernel_6103/1673918473.py:46: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(1000, tune=1000, target_accept=0.95)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, beta, sigma_beta, mu_beta, alpha, sigma_alpha, mu_alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3522' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      44.02% [3522/8000 08:15<10:30 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 1_000 tune and 197 draw iterations (1_000 + 197 draws total) took 537 seconds.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as expanded_prior_model:\n",
    "    \n",
    "    # Indexing\n",
    "    trial_idxs = pm.Data(\"trial_idxs\", df[\"trial\"].values)\n",
    "    participant_idxs = pm.Data(\"participant_idxs\", df[\"ID_idx\"].values)\n",
    "\n",
    "    # Inputs\n",
    "    SoC_last = pm.Data(\"SoC_last_trial\", df[\"SoC_last_trial\"].values)\n",
    "    N_crash_success = pm.Data(\"N_consecutive_crash_success\", df[\"N_consecutive_crash_success\"].values)\n",
    "    N_drift = pm.Data(\"N_drift\", df[\"N_drift\"].values)\n",
    "\n",
    "    # Hyperpriors for prior weights (SoC_last and crash/success history)\n",
    "    mu_alpha = pm.Normal(\"mu_alpha\", 0, 1, shape=2)\n",
    "    sigma_alpha = pm.HalfNormal(\"sigma_alpha\", 1, shape=2)\n",
    "\n",
    "    # Participant-level coefficients for prior\n",
    "    alpha = pm.Normal(\"alpha\", mu=mu_alpha, sigma=sigma_alpha, shape=(n_participants, 2))\n",
    "\n",
    "    # Compute prior: linear combo of predictors\n",
    "    prior = (\n",
    "        alpha[participant_idxs, 0] * SoC_last +\n",
    "        alpha[participant_idxs, 1] * N_crash_success\n",
    "    )\n",
    "\n",
    "    # Hyperpriors for drift weighting\n",
    "    mu_beta = pm.Normal(\"mu_beta\", 0, 1)\n",
    "    sigma_beta = pm.HalfNormal(\"sigma_beta\", 1)\n",
    "\n",
    "    beta = pm.Normal(\"beta\", mu=mu_beta, sigma=sigma_beta, shape=n_participants)\n",
    "\n",
    "    # Weight (log scale)\n",
    "    log_w = beta[participant_idxs] * trial_idxs\n",
    "    w = pm.Deterministic(\"w\", pm.math.exp(log_w))\n",
    "\n",
    "    # Posterior expectation (weighted average of prior and likelihood)\n",
    "    mu_soc = (prior + w * N_drift) / (1 + w)\n",
    "\n",
    "    # Likelihood\n",
    "    sigma = pm.HalfNormal(\"sigma\", 0.1)\n",
    "    SoC_obs = pm.Normal(\"SoC_obs\", mu=mu_soc, sigma=sigma, observed=df[\"SoC\"].values)\n",
    "\n",
    "    # Predictions\n",
    "    SoC_pred = pm.Deterministic(\"SoC_pred\", mu_soc)\n",
    "\n",
    "    # Sampling\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df775c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
